{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a713e3bc",
   "metadata": {},
   "source": [
    "## Assignments\n",
    "### Same as BDA1, but use built-in API functions for all the 5 exercises.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a420d3",
   "metadata": {},
   "source": [
    "### Q1\n",
    "#### year, station with the max, maxValue ORDER BY maxValue DESC  \n",
    "#### year, station with the min, minValue ORDER BY minValue DESC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "sc = SparkContext(appName=\"exercise 1\")\n",
    "spark = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "temperature_file = sc.textFile(\"BDA/input/temperature-readings.csv\")\n",
    "lines = temperature_file.map(lambda line: line.split(\";\"))\n",
    "\n",
    "year_temperature = lines.map(lambda x: (x[1][0:4], x[0], float(x[3])))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"year\", StringType(), True),\n",
    "    StructField(\"station\", StringType(), True),\n",
    "    StructField(\"value\", FloatType(), True)\n",
    "])\n",
    "\n",
    "year_temperature_df = sqlContext.createDataFrame(year_temperature, schema)\n",
    "\n",
    "filtered_year_temperature = year_temperature_df.filter((year_temperature_df[\"year\"] >= \"1950\") & (year_temperature_df[\"year\"] <= \"2014\"))\n",
    "\n",
    "max_temperatures = filtered_year_temperature.groupBy('year', 'station').agg(F.max('value').alias('maxValue')).orderBy(['year', 'station', 'maxValue'], ascending=[False, False, True])\n",
    "max_temperatures_combine = max_temperatures.rdd.coalesce(1)\n",
    "max_temperatures_combine = max_temperatures_combine.sortBy(lambda x: x[2], ascending=False)\n",
    "max_temperatures_combine.saveAsTextFile(\"BDA/output/l2max\")\n",
    "\n",
    "\n",
    "\n",
    "min_temperatures = filtered_year_temperature.groupBy('year', 'station').agg(F.min('value').alias('minValue')).orderBy(['year', 'station', 'minValue'], ascending=[False, False, True])\n",
    "min_temperatures_combine = min_temperatures.rdd.coalesce(1)\n",
    "min_temperatures_combine = min_temperatures_combine.sortBy(lambda x: x[2], ascending=False)\n",
    "min_temperatures_combine.saveAsTextFile(\"BDA/output/l2min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c17eaa",
   "metadata": {},
   "source": [
    "### output of l2min  \n",
    "\n",
    "Row(year=u'2010', station=u'95530', minValue=15.199999809265137)  \n",
    "Row(year=u'1979', station=u'99090', minValue=13.100000381469727)  \n",
    "Row(year=u'1984', station=u'53220', minValue=12.0)  \n",
    "Row(year=u'2001', station=u'117160', minValue=8.0)  \n",
    "Row(year=u'2010', station=u'89560', minValue=7.900000095367432)  \n",
    "Row(year=u'1998', station=u'104390', minValue=7.5)  \n",
    "Row(year=u'1986', station=u'84390', minValue=5.300000190734863)  \n",
    "Row(year=u'2009', station=u'71140', minValue=4.900000095367432)  \n",
    "Row(year=u'1970', station=u'107530', minValue=4.099999904632568)  \n",
    "Row(year=u'1955', station=u'65640', minValue=3.4000000953674316)  \n",
    "\n",
    "### output of l2max  \n",
    "\n",
    "Row(year=u'1975', station=u'86200', maxValue=36.099998474121094)  \n",
    "Row(year=u'1975', station=u'95160', maxValue=35.79999923706055)  \n",
    "Row(year=u'1975', station=u'96550', maxValue=35.599998474121094)  \n",
    "Row(year=u'1975', station=u'106100', maxValue=35.5)  \n",
    "Row(year=u'1992', station=u'63600', maxValue=35.400001525878906)  \n",
    "Row(year=u'1975', station=u'75240', maxValue=35.400001525878906)  \n",
    "Row(year=u'1992', station=u'63050', maxValue=35.20000076293945)  \n",
    "Row(year=u'1992', station=u'85040', maxValue=35.0)  \n",
    "Row(year=u'1992', station=u'76000', maxValue=35.0)  \n",
    "Row(year=u'1992', station=u'75240', maxValue=35.0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ddafe6",
   "metadata": {},
   "source": [
    "### Q2\n",
    "#### year, month, value ORDER BY value DESC  \n",
    "#### year, month, value ORDER BY value DESC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe992c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "sc = SparkContext(appName=\"exercise 1\")\n",
    "spark = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "temperature_file = sc.textFile(\"BDA/input/temperature-readings.csv\")\n",
    "lines = temperature_file.map(lambda line: line.split(\";\"))\n",
    "\n",
    "year_month_temperature = lines.map(lambda x: (x[1][0:4],x[1][5:7],x[0],float(x[3])))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"year\", StringType(), True),\n",
    "    StructField(\"month\", StringType(), True),\n",
    "    StructField(\"station\", StringType(), True),\n",
    "    StructField(\"value\", FloatType(), True)\n",
    "])\n",
    "\n",
    "year_month_temperature_df = sqlContext.createDataFrame(year_month_temperature, schema)\n",
    "\n",
    "filtered_year_month_temperature = year_month_temperature_df.filter((year_month_temperature_df[\"year\"] >= \"1950\") & (year_month_temperature_df[\"year\"] <= \"2014\")& (year_month_temperature_df[\"value\"] > 10))\n",
    "\n",
    "count_temp = filtered_year_month_temperature.groupBy([\"year\", \"month\"]).count()\n",
    "sort_count = count_temp.sort(\"count\", ascending = False)\n",
    "sort_count_combine = sort_count.rdd.coalesce(1)\n",
    "sort_count_combine = sort_count_combine.sortBy(lambda x: x[2], ascending=False)\n",
    "sort_count_combine.saveAsTextFile(\"BDA/output/l2_not_distinct\")\n",
    "\n",
    "distinct_temp = filtered_year_month_temperature.select([\"year\", \"month\", \"station\"]).distinct()\n",
    "count_dist_temp = distinct_temp.groupBy([\"year\", \"month\"]).count()\n",
    "sort_count_dist = count_dist_temp.sort(\"count\", ascending = False)\n",
    "sort_count_dist = sort_count_dist.rdd.coalesce(1)\n",
    "sort_count_dist = sort_count_dist.sortBy(lambda x: x[2], ascending=False)\n",
    "sort_count_dist.saveAsTextFile(\"BDA/output/l2_distinct\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b99717",
   "metadata": {},
   "source": [
    "### output of l2_not_distinct  \n",
    "\n",
    "Row(year=u'2014', month=u'07', count=147681)  \n",
    "Row(year=u'2011', month=u'07', count=146656)  \n",
    "Row(year=u'2010', month=u'07', count=143419)  \n",
    "Row(year=u'2012', month=u'07', count=137477)  \n",
    "Row(year=u'2013', month=u'07', count=133657)  \n",
    "Row(year=u'2009', month=u'07', count=133008)  \n",
    "Row(year=u'2011', month=u'08', count=132734)  \n",
    "Row(year=u'2009', month=u'08', count=128349)  \n",
    "Row(year=u'2013', month=u'08', count=128235)  \n",
    "Row(year=u'2003', month=u'07', count=128133)  \n",
    "  \n",
    "### output of l2_distinct \n",
    "\n",
    "Row(year=u'1972', month=u'10', count=378)  \n",
    "Row(year=u'1973', month=u'05', count=377)  \n",
    "Row(year=u'1973', month=u'06', count=377)  \n",
    "Row(year=u'1972', month=u'08', count=376)  \n",
    "Row(year=u'1973', month=u'09', count=376)  \n",
    "Row(year=u'1972', month=u'06', count=375)  \n",
    "Row(year=u'1972', month=u'09', count=375)  \n",
    "Row(year=u'1971', month=u'08', count=375)  \n",
    "Row(year=u'1972', month=u'05', count=375)  \n",
    "Row(year=u'1971', month=u'06', count=374)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab631d2",
   "metadata": {},
   "source": [
    "### Q4\n",
    "#### station, maxTemp, maxDailyPrecipitation ORDER BY station DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0677e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "sc = SparkContext(appName=\"exercise 1\")\n",
    "spark = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "temperature_file = sc.textFile(\"BDA/input/temperature-readings.csv\")\n",
    "temperature_lines = temperature_file.map(lambda line: line.split(\";\"))\n",
    "get_temperature = temperature_lines.map(lambda x: (x[0],float(x[3])))\n",
    "tempschema = StructType([\n",
    "    StructField(\"station\", StringType(), True),\n",
    "    StructField(\"temp\", FloatType(), True)\n",
    "])\n",
    "temperature_df = sqlContext.createDataFrame(get_temperature, tempschema)\n",
    "station_max_temp = temperature_df.groupBy(\"station\").agg(F.max(\"temp\").alias('temp'))\n",
    "filter_temp = station_max_temp.filter((station_max_temp[\"temp\"] >= \"25\") & (station_max_temp[\"temp\"] <= \"30\"))\n",
    "\n",
    "precipitation_file = sc.textFile(\"BDA/input/precipitation-readings.csv\")\n",
    "precipitation_file = precipitation_file.map(lambda line: line.split(\";\"))\n",
    "get_percipitation = precipitation_file.map(lambda x: (x[0],float(x[3])))\n",
    "precschema = StructType([\n",
    "    StructField(\"station\", StringType(), True),\n",
    "    StructField(\"prec\", FloatType(), True)\n",
    "])\n",
    "percipitation_df = sqlContext.createDataFrame(get_percipitation, precschema)\n",
    "station_max_perc = percipitation_df.groupBy(\"station\").agg(F.max(\"prec\").alias('prec'))\n",
    "filter_perc = station_max_perc.filter((station_max_perc[\"prec\"] >= \"100\") & (station_max_perc[\"prec\"] <= \"200\"))\n",
    "\n",
    "combine_temp_perc = filter_temp.join(filter_perc.alias('perc'), 'station', 'inner')\n",
    "\n",
    "#output\n",
    "combine_temp_perc_combine = combine_temp_perc.rdd.coalesce(1)\n",
    "filter_temp_combine = combine_temp_perc_combine.sortBy(lambda x: x[0], ascending=False)\n",
    "filter_temp_combine.saveAsTextFile(\"BDA/output/l2_perc_temp\")\n",
    "\n",
    "\n",
    "#Testoutput\n",
    "#filter_temp_combine = filter_temp.rdd.coalesce(1)\n",
    "#filter_temp_combine = filter_temp_combine.sortBy(lambda x: x[0], ascending=False)\n",
    "#filter_temp_combine.saveAsTextFile(\"BDA/output/l2_temptest\")\n",
    "\n",
    "#filter_perc_combine = filter_perc.rdd.coalesce(1)\n",
    "#filter_perc_combine = filter_perc_combine.sortBy(lambda x: x[0], ascending=False)\n",
    "#filter_perc_combine.saveAsTextFile(\"BDA/output/l2_perctest\")\n",
    "\n",
    "#combine_temp_perc_combine = combine_temp_perc.rdd.coalesce(1)\n",
    "#filter_temp_combine = combine_temp_perc_combine.sortBy(lambda x: x[0], ascending=False)\n",
    "#filter_temp_combine.saveAsTextFile(\"BDA/output/l2_combtest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd8ca9b",
   "metadata": {},
   "source": [
    "### output of l2_perc_temp is empty, since no data meet the criteria"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
